// RobotBuilder Version: 2.0
//
// This file was generated by RobotBuilder. It contains sections of
// code that are automatically generated and assigned by robotbuilder.
// These sections will be updated in the future when you export to
// Java from RobotBuilder. Do not put any code or make any change in
// the blocks indicating autogenerated code or it will be lost on an
// update. Deleting the comments indicating the section will prevent
// it from being updated in the future.


package org.usfirst.frc4914.threestagevision;

import edu.wpi.first.wpilibj.CameraServer;
import edu.wpi.first.wpilibj.IterativeRobot;
import edu.wpi.first.wpilibj.command.Command;
import edu.wpi.first.wpilibj.command.Scheduler;
import edu.wpi.first.wpilibj.livewindow.LiveWindow;
import edu.wpi.first.wpilibj.smartdashboard.SmartDashboard;
import edu.wpi.first.wpilibj.vision.USBCamera;

import java.util.Comparator;
import java.util.Vector;

import org.usfirst.frc4914.threestagevision.Robot;
import org.usfirst.frc4914.threestagevision.commands.*;
import org.usfirst.frc4914.threestagevision.subsystems.*;

import com.ni.vision.NIVision;
import com.ni.vision.NIVision.Image;
import com.ni.vision.NIVision.ImageType;

/**
 * The VM is configured to automatically run this class, and to call the
 * functions corresponding to each mode, as described in the IterativeRobot
 * documentation. If you change the name of this class or the package after
 * creating this project, you must also update the manifest file in the resource
 * directory.
 */
public class Robot extends IterativeRobot {
	
	/**
	 * A structure to hold measurements of a particle.<br>
	 * 
	 * PercentAreaToImageArea - <br>
	 * Area - <br>
	 * BoundingRectLeft - <br>
	 * BoundingRectTop - <br>
	 * BoundingRectRight - <br>
	 * BoundingRectBottom - <br>
	 */
	public class ParticleReport implements Comparator<ParticleReport>, Comparable<ParticleReport>{
		double PercentAreaToImageArea;
		double Area;
		double BoundingRectLeft;
		double BoundingRectTop;
		double BoundingRectRight;
		double BoundingRectBottom;
		
		public int compareTo(ParticleReport r)
		{
			return (int)(r.Area - this.Area);
		}
		
		public int compare(ParticleReport r1, ParticleReport r2)
		{
			return (int)(r1.Area - r2.Area);
		}
	};

	/**
	 * A structure to represent the scores for the various tests used for target identification.<br>
	 * 
	 * Area - <br>
	 * Aspect - <br>
	 */
	public class Scores {
		double Area;
		double Aspect;
	};
	
	static int session;
	USBCamera cam1;
	Image frame;
	Image binaryFrame;
	int imaqError;

    Command autonomousCommand;

    public static OI oi;
    // BEGIN AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=DECLARATIONS
    public static Drivetrain drivetrain;
    public static Shooter shooter;

    // END AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=DECLARATIONS

    NIVision.Range GOAL_HUE_RANGE = new NIVision.Range(100, 255);	//Default hue range for yellow goal
	NIVision.Range GOAL_SAT_RANGE = new NIVision.Range(150, 255);	//Default saturation range for yellow goal
	NIVision.Range GOAL_VAL_RANGE = new NIVision.Range(100, 255);	//Default value range for yellow goal
	double AREA_MINIMUM = 1; //Default Area minimum for particle as a percentage of total image area
	double RATIO_MIN = 1; //Goal width = 20in / Goal height = 12in = 1.66
	double RATIO_MAX = 2.3;
	double SCORE_MIN = 75.0;  //Minimum score to be considered a goal
	double VIEW_ANGLE = 60; //Camera view angle, set to Axis m1011 by default, 64 for m1013, 51.7 for 206, 52 for HD3000 square, 60 for HD3000 640x480
	NIVision.ParticleFilterCriteria2 criteria[] = new NIVision.ParticleFilterCriteria2[1];
	NIVision.ParticleFilterOptions2 filterOptions = new NIVision.ParticleFilterOptions2(0,0,1,1);
	Scores scores = new Scores();
    
    /**
     * This function is run when the robot is first started up and should be
     * used for any initialization code.
     */
    public void robotInit() {
    RobotMap.init();
        // BEGIN AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=CONSTRUCTORS
        drivetrain = new Drivetrain();
        shooter = new Shooter();

        // END AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=CONSTRUCTORS
        // OI must be constructed after subsystems. If the OI creates Commands
        //(which it very likely will), subsystems are not guaranteed to be
        // constructed yet. Thus, their requires() statements may grab null
        // pointers. Bad news. Don't move it.
        oi = new OI();

        // instantiate the command used for the autonomous period
        // BEGIN AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=AUTONOMOUS

        autonomousCommand = new AutonomousCommand();

        // END AUTOGENERATED CODE, SOURCE=ROBOTBUILDER ID=AUTONOMOUS
        
        frame = NIVision.imaqCreateImage(NIVision.ImageType.IMAGE_RGB, 1);
        binaryFrame = NIVision.imaqCreateImage(ImageType.IMAGE_U8, 0);
 		criteria[0] = new NIVision.ParticleFilterCriteria2(NIVision.MeasurementType.MT_AREA_BY_IMAGE_AREA, AREA_MINIMUM, 100.0, 0, 0);
 		 		
 		session = NIVision.IMAQdxOpenCamera("cam1",
                 NIVision.IMAQdxCameraControlMode.CameraControlModeController);
 		// NIVision.IMAQdxSetAttributeI64(session, "CameraAttributes::Exposure::Mode", 1);
        NIVision.IMAQdxConfigureGrab(session);
        NIVision.IMAQdxStartAcquisition(session);

 		//Put default values to SmartDashboard so fields will appear
 		SmartDashboard.putNumber("Goal hue min", GOAL_HUE_RANGE.minValue);
 		SmartDashboard.putNumber("Goal hue max", GOAL_HUE_RANGE.maxValue);
 		SmartDashboard.putNumber("Goal sat min", GOAL_SAT_RANGE.minValue);
 		SmartDashboard.putNumber("Goal sat max", GOAL_SAT_RANGE.maxValue);
 		SmartDashboard.putNumber("Goal val min", GOAL_VAL_RANGE.minValue);
 		SmartDashboard.putNumber("Goal val max", GOAL_VAL_RANGE.maxValue);
 		SmartDashboard.putNumber("Area min %", AREA_MINIMUM);
     	
    }

    /**
     * This function is called when the disabled button is hit.
     * You can use it to reset subsystems before shutting down.
     */
    public void disabledInit(){
    	// safely stops all subsystems
    	Robot.drivetrain.stop();
    	Robot.shooter.stop();
    }

    public void disabledPeriodic() {
        Scheduler.getInstance().run();
    }

    public void autonomousInit() {
        // schedule the autonomous command (example)
        if (autonomousCommand != null) autonomousCommand.start();
    }

    /**
     * This function is called periodically during autonomous
     */
    public void autonomousPeriodic() {
        Scheduler.getInstance().run();
    }

    public void teleopInit() {
        // This makes sure that the autonomous stops running when
        // teleop starts running. If you want the autonomous to
        // continue until interrupted by another command, remove
        // this line or comment it out.
        if (autonomousCommand != null) autonomousCommand.cancel();
    }

    /**
     * This function is called periodically during operator control
     */
    public void teleopPeriodic() {
        Scheduler.getInstance().run();
        
        boolean inverted = Robot.drivetrain.inverted;
        double lSpeed = 0;
        double rSpeed = 0;

        // driver inputs
        lSpeed += Robot.oi.driverLJ();
        rSpeed += Robot.oi.driverRJ();
        
        if (inverted) { // switches left and right speeds and multiplies by -1
        	double temp = lSpeed;
        	lSpeed = -rSpeed;
        	rSpeed = -temp;
        }
        
        // codriver fine turning
        lSpeed += Robot.oi.codriverZ() * 0.35;
        rSpeed += -Robot.oi.codriverZ() * 0.35;
        
        // codriver fine distance
        /*
        lSpeed += Robot.oi.codriverX() * 0.25;
        rSpeed += Robot.oi.codriverX() * 0.25;
        */
        
        // passing values to speed controllers
        Robot.drivetrain.setLeftSide(lSpeed);
        Robot.drivetrain.setRightSide(rSpeed);
        
        // DEBUG
        // System.out.println("Top: " + Robot.shooter.getBottomFlywheelSpeed());
        // System.out.println("Btm: " + Robot.shooter.getTopFlywheelSpeed());
        
        if (visionEnableds) {

            
            NIVision.IMAQdxGrab(session, frame, 1);
    		//Update threshold values from SmartDashboard. For performance reasons it is recommended to remove this after calibration is finished.
    		GOAL_HUE_RANGE.minValue = (int)SmartDashboard.getNumber("Goal hue min", GOAL_HUE_RANGE.minValue);
    		GOAL_HUE_RANGE.maxValue = (int)SmartDashboard.getNumber("Goal hue max", GOAL_HUE_RANGE.maxValue);
    		GOAL_SAT_RANGE.minValue = (int)SmartDashboard.getNumber("Goal sat min", GOAL_SAT_RANGE.minValue);
    		GOAL_SAT_RANGE.maxValue = (int)SmartDashboard.getNumber("Goal sat max", GOAL_SAT_RANGE.maxValue);
    		GOAL_VAL_RANGE.minValue = (int)SmartDashboard.getNumber("Goal val min", GOAL_VAL_RANGE.minValue);
    		GOAL_VAL_RANGE.maxValue = (int)SmartDashboard.getNumber("Goal val max", GOAL_VAL_RANGE.maxValue);

    		//Threshold the image looking for yellow (goal color)
    		NIVision.imaqColorThreshold(binaryFrame, frame, 255, NIVision.ColorMode.HSV, GOAL_HUE_RANGE, GOAL_SAT_RANGE, GOAL_VAL_RANGE);

    		//Send particle count to dashboard
    		int numParticles = NIVision.imaqCountParticles(binaryFrame, 1);
    		SmartDashboard.putNumber("Masked particles", numParticles);

    		//Send masked image to dashboard to assist in tweaking mask.
    		CameraServer.getInstance().setImage(binaryFrame);

    		//filter out small particles
    		float areaMin = (float)SmartDashboard.getNumber("Area min %", AREA_MINIMUM);
    		criteria[0].lower = areaMin;
    		imaqError = NIVision.imaqParticleFilter4(binaryFrame, binaryFrame, criteria, filterOptions, null);

    		//Send particle count after filtering to dashboard
    		numParticles = NIVision.imaqCountParticles(binaryFrame, 1);
    		SmartDashboard.putNumber("Filtered particles", numParticles);

    		if(numParticles > 0)
    		{
    			//Measure particles and sort by particle size
    			Vector<ParticleReport> particles = new Vector<ParticleReport>();
    			for(int particleIndex = 0; particleIndex < numParticles; particleIndex++)
    			{
    				ParticleReport par = new ParticleReport();
    				par.PercentAreaToImageArea = NIVision.imaqMeasureParticle(binaryFrame, particleIndex, 0, NIVision.MeasurementType.MT_AREA_BY_IMAGE_AREA);
    				par.Area = NIVision.imaqMeasureParticle(binaryFrame, particleIndex, 0, NIVision.MeasurementType.MT_AREA);
    				par.BoundingRectTop = NIVision.imaqMeasureParticle(binaryFrame, particleIndex, 0, NIVision.MeasurementType.MT_BOUNDING_RECT_TOP);
    				par.BoundingRectLeft = NIVision.imaqMeasureParticle(binaryFrame, particleIndex, 0, NIVision.MeasurementType.MT_BOUNDING_RECT_LEFT);
    				par.BoundingRectBottom = NIVision.imaqMeasureParticle(binaryFrame, particleIndex, 0, NIVision.MeasurementType.MT_BOUNDING_RECT_BOTTOM);
    				par.BoundingRectRight = NIVision.imaqMeasureParticle(binaryFrame, particleIndex, 0, NIVision.MeasurementType.MT_BOUNDING_RECT_RIGHT);
    				particles.add(par);
    			}
    			particles.sort(null);

    			SmartDashboard.putNumber("Right", particles.elementAt(0).BoundingRectRight);
    			SmartDashboard.putNumber("Left", particles.elementAt(0).BoundingRectLeft);
    			SmartDashboard.putNumber("Top", particles.elementAt(0).BoundingRectTop);
    			SmartDashboard.putNumber("Bottom", particles.elementAt(0).BoundingRectBottom);

    			//This example only scores the largest particle. Extending to score all particles and choosing the desired one is left as an exercise
    			//for the reader. Note that this scores and reports information about a single particle (single L shaped target). To get accurate information 
    			//about the location of the goal (not just the distance) you will need to correlate two adjacent targets in order to find the true center of the goal.
    			scores.Aspect = AspectScore(particles.elementAt(0));
    			SmartDashboard.putNumber("Aspect", scores.Aspect);
    			scores.Area = AreaScore(particles.elementAt(0));
    			SmartDashboard.putNumber("Area", scores.Area);
    			boolean isGoal = scores.Aspect > RATIO_MIN && scores.Aspect < RATIO_MAX;

    			//Send distance and goal status to dashboard. The bounding rect, particularly the horizontal center (left - right) may be useful for rotating/driving towards a goal
    			SmartDashboard.putBoolean("IsGoal", isGoal);
    			SmartDashboard.putNumber("Distance", computeDistance(binaryFrame, particles.elementAt(0)));
    		} else {
    			SmartDashboard.putBoolean("IsGoal", false);
    		}
        } // end of if (visionEnabled)
    }

    /**
     * This function is called periodically during test mode
     */
    public void testPeriodic() {
        LiveWindow.run();
    }
    


	//Comparator function for sorting particles. Returns true if particle 1 is larger
	static boolean CompareParticleSizes(ParticleReport particle1, ParticleReport particle2)
	{
		//we want descending sort order
		return particle1.PercentAreaToImageArea > particle2.PercentAreaToImageArea;
	}

	/**
	 * Converts a ratio with ideal value of 1 to a score. The resulting function is piecewise
	 * linear going from (0,0) to (1,100) to (2,0) and is 0 for all inputs outside the range 0-2
	 */
	double ratioToScore(double ratio)
	{
		return (Math.max(0, Math.min(100*(1-Math.abs(1-ratio)), 100)));
	}

	double AreaScore(ParticleReport report)
	{
		double boundingArea = (report.BoundingRectBottom - report.BoundingRectTop) * (report.BoundingRectRight - report.BoundingRectLeft);
		//Tape is 7" edge so 49" bounding rect. With 2" wide tape it covers 24" of the rect.
		return ratioToScore((49/24)*report.Area/boundingArea);
	}

	/**
	 * Method to score if the aspect ratio of the particle appears to match the retro-reflective target. Target is 7"x7" so aspect should be 1
	 */
	double AspectScore(ParticleReport report)
	{
		return (report.BoundingRectRight-report.BoundingRectLeft)/(report.BoundingRectBottom-report.BoundingRectTop);
	}

	/**
	 * Computes the estimated distance to a target using the width of the particle in the image. For more information and graphics
	 * showing the math behind this approach see the Vision Processing section of the ScreenStepsLive documentation.
	 *
	 * @param image The image to use for measuring the particle estimated rectangle
	 * @param report The Particle Analysis Report for the particle
	 * @return The estimated distance to the target in feet.
	 */
	double computeDistance (Image image, ParticleReport report) {
		double normalizedWidth, targetWidth;
		NIVision.GetImageSizeResult size;

		size = NIVision.imaqGetImageSize(image);
		normalizedWidth = 2*(report.BoundingRectRight - report.BoundingRectLeft)/size.width;
		targetWidth = 7;

		return  targetWidth/(normalizedWidth*12*Math.tan(VIEW_ANGLE*Math.PI/(180*2)));
	}
}
